{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latihan 1 | Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, math, sys\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from collections import defaultdict\n",
    "import sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(sentence, index):\n",
    "    \n",
    "    currWord = sentence[index][0]\n",
    "    \n",
    "    if (index > 0):\n",
    "        prevWord = sentence[index - 1][0]\n",
    "    else:\n",
    "        prevWord = '<START>'\n",
    "        \n",
    "    if (index < len(sentence)-1):\n",
    "        nextWord = sentence[index + 1][0]\n",
    "    else:\n",
    "        nextWord = '<END>'\n",
    "        \n",
    "    return {\n",
    "        'word' : currWord,\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'curr_is_title': currWord.istitle(),\n",
    "        'prev_is_title': prevWord.istitle(),\n",
    "        'next_is_title': nextWord.istitle(),\n",
    "        'curr_is_lower': currWord.islower(),\n",
    "        'prev_is_lower': prevWord.islower(),\n",
    "        'next_is_lower': nextWord.islower(),\n",
    "        'curr_is_upper': currWord.isupper(),\n",
    "        'prev_is_upper': prevWord.isupper(),\n",
    "        'next_is_upper': nextWord.isupper(),\n",
    "        'curr_is_digit': currWord.isdigit(),\n",
    "        'prev_is_digit': prevWord.isdigit(),\n",
    "        'next_is_digit': nextWord.isdigit(),\n",
    "        'curr_prefix-1': currWord[0],\n",
    "        'curr_prefix-2': currWord[:2],\n",
    "        'curr_prefix-3': currWord[:3],\n",
    "        'curr_suffix-1': currWord[-1],\n",
    "        'curr_suffix-2': currWord[-2:],\n",
    "        'curr_suffix-3': currWord[-3:],\n",
    "        'prev_prefix-1': currWord[0],\n",
    "        'prev_prefix-2': currWord[:2],\n",
    "        'prev_prefix-3': currWord[:3],\n",
    "        'prev_suffix-1': prevWord[-1],\n",
    "        'prev_suffix-2': prevWord[-2:],\n",
    "        'prev_suffix-3': prevWord[-3:],\n",
    "        'next_prefix-1': nextWord[0],\n",
    "        'next_prefix-2': nextWord[:2],\n",
    "        'next_prefix-3': nextWord[:3],\n",
    "        'next_suffix-1': nextWord[-1],\n",
    "        'next_suffix-2': nextWord[-2:],\n",
    "        'next_suffix-3': nextWord[-3:],\n",
    "        'prev_word': prevWord,\n",
    "        'next_word': nextWord,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTagProbs(trainLabels, tagsDict):\n",
    "    numTags = len(tagsDict)\n",
    "    tagProbs = np.zeros(numTags)\n",
    "    for sentenceLabels in trainLabels:\n",
    "        for tag in sentenceLabels:\n",
    "            tagProbs[tagsDict[tag]] += 1\n",
    "    tagProbs += 1\n",
    "    return tagProbs / np.sum(tagProbs)\n",
    "\n",
    "def computeStartProbs(trainLabels, tagsDict):\n",
    "    numTags = len(tagsDict)\n",
    "    startProbs = np.zeros(numTags)\n",
    "    for sentenceLabels in trainLabels:\n",
    "        startTag = sentenceLabels[0]\n",
    "        startProbs[tagsDict[startTag]] += 1\n",
    "    startProbs += 1\n",
    "    return startProbs/np.sum(startProbs)\n",
    "\n",
    "def computeTransitionProbabilities(trainLabels, tagsDict):\n",
    "    numTags = len(tagsDict)\n",
    "    transMat = np.zeros(shape=(numTags, numTags))\n",
    "    for sentenceLabels in trainLabels:\n",
    "        for i in range(len(sentenceLabels)-1):\n",
    "            tag1 = tagsDict[sentenceLabels[i]]\n",
    "            tag2 = tagsDict[sentenceLabels[i+1]]\n",
    "            transMat[tag1, tag2] += 1\n",
    "    normalized_transmat = normalize(transMat+1, axis=1, norm='l1')\n",
    "    return normalized_transmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEmissionProbabilities(trainFeatures, trainLabels, tagsDict):\n",
    "    numTags = len(tagsDict)\n",
    "    emissionDict = defaultdict(lambda: defaultdict(int))\n",
    "    uniqueKeys = set()\n",
    "    for i in range(len(trainLabels)):\n",
    "        sentenceFeatures = trainFeatures[i]\n",
    "        sentenceLabels = trainLabels[i]\n",
    "        for j in range(len(sentenceLabels)):\n",
    "            tag = sentenceLabels[j]\n",
    "            for key, val in sentenceFeatures[j].items():\n",
    "                transformedKey = str(key) + \"__\" + str(val)\n",
    "                uniqueKeys.add(transformedKey)\n",
    "                emissionDict[tag][transformedKey] += 1\n",
    "    emissionMat = np.zeros(shape=(numTags, len(uniqueKeys)))\n",
    "    featuresDict = {}\n",
    "    for index, key in enumerate(uniqueKeys):\n",
    "        featuresDict[key] = index\n",
    "    for tag in tagsDict.keys():\n",
    "        for key in featuresDict.keys():\n",
    "            i = tagsDict[tag]\n",
    "            j = featuresDict[key]\n",
    "            emissionMat[i, j] = emissionDict[tag][key]\n",
    "    normalized_emissionMat = normalize(emissionMat+1, axis=1, norm='l1')\n",
    "    return normalized_emissionMat, featuresDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictTags(testFeatures, tagProbs, startProbs, transMat, emissionMat,\n",
    "                tagsDict, featuresDict):\n",
    "    numTags = len(tagsDict)\n",
    "    bestTags = []\n",
    "    for sentenceFeatures in testFeatures:\n",
    "        bestTagsSentence = []\n",
    "        lenSentence = len(sentenceFeatures)\n",
    "        probMatrix, tagMatrix = np.zeros(shape=(lenSentence, numTags)), np.zeros(shape=(lenSentence, numTags))\n",
    "        for index in range(lenSentence):\n",
    "            feat = sentenceFeatures[index]\n",
    "            for curr in range(numTags):\n",
    "                emissionProb = 0\n",
    "                for key, val in feat.items():\n",
    "                    transformedKey = str(key) + \"__\" + str(val)\n",
    "                    if transformedKey in featuresDict:\n",
    "                        emissionProb += \\\n",
    "                        math.log(emissionMat[curr,\n",
    "                                             featuresDict[transformedKey]])\n",
    "                    else:\n",
    "                        emissionProb -= math.log(len(featuresDict))\n",
    "                emissionProb += math.log(tagProbs[curr])\n",
    "                maxProb = -sys.float_info.max\n",
    "                maxProbTag = -1\n",
    "                if index == 0:\n",
    "                    probMatrix[index][curr] = \\\n",
    "                    math.log(startProbs[curr]) + emissionProb\n",
    "                    tagMatrix[index][curr] = -1\n",
    "                else:\n",
    "                    for prev in range (numTags):\n",
    "                        tagProb = \\\n",
    "                        math.log(transMat[prev, curr]) + \\\n",
    "                        math.log(probMatrix[index - 1][prev])\n",
    "                        if (tagProb > maxProb):\n",
    "                            maxProb = tagProb\n",
    "                            maxProbTag = prev\n",
    "                    maxProb += emissionProb\n",
    "                    probMatrix[index][curr] = maxProb\n",
    "                    tagMatrix[index][curr] = maxProbTag\n",
    "            const = -np.mean(probMatrix[index])\n",
    "            func = np.vectorize(lambda t: math.exp(t+const))\n",
    "            probMatrix[index] = func(probMatrix[index])\n",
    "            probMatrix = normalize(probMatrix, axis=1, norm='l1')\n",
    "        prevBestTag = None\n",
    "        for index in reversed(range(lenSentence+1)):\n",
    "            if index == lenSentence:\n",
    "                bestTag = probMatrix[index-1].argmax()\n",
    "            else:\n",
    "                bestTag = tagMatrix[index][prevBestTag]\n",
    "            prevBestTag = int(bestTag)\n",
    "            bestTagsSentence.append(prevBestTag)\n",
    "        bestTags.append(list(reversed(bestTagsSentence))[1:])\n",
    "    return bestTags\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformDatasetSequence(sentences):\n",
    "    wordFeatures, wordLabels = [], []\n",
    "    for sent in sentences:\n",
    "        feats, labels = [], []\n",
    "        for index in range(len(sent)):\n",
    "            feats.append(features(sent, index))\n",
    "            labels.append(sent[index][1])\n",
    "        wordFeatures.append(feats)\n",
    "        wordLabels.append(labels)\n",
    "    return wordFeatures, wordLabels\n",
    "\n",
    "def trainHMM(trainFeatures, trainLabels, tagsDict):\n",
    "    tagProbs = computeTagProbs(trainLabels, tagsDict)\n",
    "    startProbs = computeStartProbs(trainLabels, tagsDict)\n",
    "    transMat = computeTransitionProbabilities(trainLabels, tagsDict)\n",
    "    emissionMat, featuresDict = computeEmissionProbabilities(trainFeatures,\n",
    "                                                             trainLabels,\n",
    "                                                             tagsDict)\n",
    "    return tagProbs, startProbs, transMat, emissionMat, featuresDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSeqAccuracy(predictedTags, actualTags):\n",
    "    total, correct = 0, 0\n",
    "    \n",
    "    for i in range(len(predictedTags)):\n",
    "        for j in range(len(predictedTags[i])):\n",
    "            total += 1\n",
    "            if predictedTags[i][j] == actualTags[i][j]:\n",
    "                correct += 1\n",
    "                \n",
    "    return float(correct)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "import nltk\n",
    "nltk.download('brown')\n",
    "\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "\n",
    "size = int(len(brown_tagged_sents) * 0.7)\n",
    "\n",
    "tags = [tag for (word, tag) in brown.tagged_words()]\n",
    "defaultTag = nltk.FreqDist(tags).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7774774774774775\n"
     ]
    }
   ],
   "source": [
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]\n",
    "\n",
    "tagsDict = {}\n",
    "for index, tag in enumerate(set(tags)):\n",
    "    tagsDict[tag] = index\n",
    "    \n",
    "trainSeqFeatures, trainSeqLabels = transformDatasetSequence(train_sents)\n",
    "testSeqFeatures, testSeqLabels = transformDatasetSequence(test_sents)\n",
    "\n",
    "tagProbs, startProbs, transMat, emissionMat, featuresDict = \\\n",
    "trainHMM(trainSeqFeatures[:30000], trainSeqLabels[:30000], tagsDict)\n",
    "\n",
    "predictedTags = predictTags(testSeqFeatures[:100], tagProbs,\n",
    "                            startProbs, transMat,\n",
    "                            emissionMat, tagsDict, featuresDict)\n",
    "print(computeSeqAccuracy(predictedTags, \\\n",
    "                         [[tagsDict[tag] for tag in tags] \\\n",
    "                          for tags in testSeqLabels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latihan 2 | Conditional Random Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5103643415781777\n"
     ]
    }
   ],
   "source": [
    "def trainCRF(trainFeatures, trainLabels):\n",
    "    crf = sklearn_crfsuite.CRF(\n",
    "        algorithm='lbfgs',\n",
    "        c1=0.1,\n",
    "        c2=0.1,\n",
    "        max_iterations=100,\n",
    "        all_possible_transitions=True,\n",
    "    )\n",
    "    crf.fit(trainFeatures, trainLabels)\n",
    "    return crf\n",
    "\n",
    "crf_model = trainCRF(trainSeqFeatures[:5], trainSeqLabels[:5])\n",
    "pred_labels = crf_model.predict(testSeqFeatures)\n",
    "print(computeSeqAccuracy(pred_labels, testSeqLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
