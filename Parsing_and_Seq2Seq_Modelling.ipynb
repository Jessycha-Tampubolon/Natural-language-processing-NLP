{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 | Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1 | Ubiquitous Ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP NP\n",
    "PP -> N NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'an' | 'my'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "sent = ['I', 'shot', 'an', 'elephant', 'in', 'pajamas']\n",
    "parser = nltk.ChartParser(groucho_grammar)\n",
    "trees = parser.parse(sent)\n",
    "for t in trees:\n",
    "    print(t)\n",
    "    t.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.2 | Recursive Descent Parsing With Context Free Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP NP\n",
    "VP -> V NP | V NP PP\n",
    "PP -> P NP\n",
    "V -> \"saw\" | \"ate\" | \"walked\"\n",
    "NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
    "N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "\"\"\")\n",
    "\n",
    "sent = \"Mary saw Bob\".split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "for t in rd_parser.parse(sent):\n",
    "    print(t)\n",
    "    t.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"the dog saw a man in the park\".split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "for t in rd_parser.parse(sent):\n",
    "    print(t)\n",
    "    t.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.3 | Chart Parsing With Context Free Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_wfst(token, grammar):\n",
    "    numtokens = len(tokens)\n",
    "    wfst = [[None for i in range(numtokens+1)] for j in range(numtokens+1)]\n",
    "    for i in range(numtokens):\n",
    "        productions = grammar.productions(rhs=token[i])\n",
    "        wfst[i][i+1] = productions[0].lhs()\n",
    "    return wfst\n",
    "\n",
    "def complete_wfst(wfst, tokens, grammar, trace=False):\n",
    "    index = dict((p.rhs(), p.lhs()) for p in grammar.productions())\n",
    "    numtokens = len(tokens)\n",
    "    for span in range(2, numtokens+1):\n",
    "        for start in range(numtokens+1-span):\n",
    "            end = start + span\n",
    "            for mid in range(start+1, end):\n",
    "                nt1, nt2 = wfst[start][mid], wfst[mid][end]\n",
    "                if nt1 and nt2 and (nt1,nt2) in index:\n",
    "                    wfst[start][end] = index[(nt1,nt2)]\n",
    "                    if trace:\n",
    "                        print(\"[%s] %3s [%s] %3s [%s] %3s [==> [%s] %3s] [%s]\" % \\\n",
    "                              (start, nt1, mid, nt2, end, start, index[(nt1,nt2)], end))\n",
    "    return wfst\n",
    "\n",
    "def display(wfst, tokens):\n",
    "    print('\\nWFST' + ''.join((\"%-4d\" % i) for i in range (1, len(wfst))))\n",
    "    for i in range(len(wfst)-1):\n",
    "        print(\"%d \" % i, end=\"\")\n",
    "        for j in range(1, len(wfst)):\n",
    "            print(\"%-4s\" %(wfst[i][j] or '.'), end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WFST1   2   3   4   5   6   7   \n",
      "0 NP   .    .    .    .    .    .    \n",
      "1 .    V    .    .    .    .    .    \n",
      "2 .    .    Det  .    .    .    .    \n",
      "3 .    .    .    N    .    .    .    \n",
      "4 .    .    .    .    P    .    .    \n",
      "5 .    .    .    .    .    Det  .    \n",
      "6 .    .    .    .    .    .    N    \n"
     ]
    }
   ],
   "source": [
    "tokens = \"I shot an elephant in my pajamas\".split()\n",
    "wfst0 = init_wfst(tokens, groucho_grammar)\n",
    "display(wfst0, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WFST1   2   3   4   5   6   7   \n",
      "0 NP   .    .    .    .    .    .    \n",
      "1 .    V    .    VP   .    .    .    \n",
      "2 .    .    Det  NP   .    .    .    \n",
      "3 .    .    .    N    .    .    .    \n",
      "4 .    .    .    .    P    .    .    \n",
      "5 .    .    .    .    .    Det  NP   \n",
      "6 .    .    .    .    .    .    N    \n"
     ]
    }
   ],
   "source": [
    "wfst1 = complete_wfst(wfst0, tokens, groucho_grammar)\n",
    "display(wfst1, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
