{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latihan 1 | Understanding Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import alpino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package alpino to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\alpino.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('alpino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = ngrams(alpino.words(),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('De',)\n",
      "('verzekeringsmaatschappijen',)\n",
      "('verhelen',)\n",
      "('niet',)\n",
      "('dat',)\n"
     ]
    }
   ],
   "source": [
    "for i, gram in enumerate(unigrams):\n",
    "    if i < 5:\n",
    "        print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadgrams = ngrams(alpino.words(),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\webtext.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('webtext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('De', 'verzekeringsmaatschappijen', 'verhelen', 'niet')\n",
      "('verzekeringsmaatschappijen', 'verhelen', 'niet', 'dat')\n",
      "('verhelen', 'niet', 'dat', 'ook')\n",
      "('niet', 'dat', 'ook', 'de')\n",
      "('dat', 'ook', 'de', 'rentegrondslag')\n"
     ]
    }
   ],
   "source": [
    "for i, gram in enumerate(quadgrams):\n",
    "    if i < 5:\n",
    "        print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'\", 's'),\n",
       " ('arthur', ':'),\n",
       " ('#', '1'),\n",
       " (\"'\", 't'),\n",
       " ('villager', '#'),\n",
       " ('#', '2'),\n",
       " (']', '['),\n",
       " ('1', ':'),\n",
       " ('oh', ','),\n",
       " ('black', 'knight')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.corpus import webtext\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "tokens = [t.lower() for t in webtext.words('grail.txt')]\n",
    "words = BigramCollocationFinder.from_words(tokens)\n",
    "words.nbest(BigramAssocMeasures.likelihood_ratio, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('black', 'knight'),\n",
       " ('clop', 'clop'),\n",
       " ('head', 'knight'),\n",
       " ('mumble', 'mumble'),\n",
       " ('squeak', 'squeak'),\n",
       " ('saw', 'saw'),\n",
       " ('holy', 'grail'),\n",
       " ('run', 'away'),\n",
       " ('french', 'guard'),\n",
       " ('cartoon', 'character')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "set = set(stopwords.words('english'))\n",
    "stops_filter = lambda w: len(w) < 3 or w in set\n",
    "tokens = [t.lower() for t in webtext.words('grail.txt')]\n",
    "words = BigramCollocationFinder.from_words(tokens)\n",
    "words.apply_word_filter(stops_filter)\n",
    "words.nbest(BigramAssocMeasures.likelihood_ratio, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 'Never'),\n",
       " ('Hardwork', 'is'),\n",
       " ('Never', 'give'),\n",
       " ('give', 'up'),\n",
       " ('is', 'the'),\n",
       " ('key', 'to'),\n",
       " ('success', '.'),\n",
       " ('the', 'key'),\n",
       " ('to', 'success'),\n",
       " ('up', '!')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"Hardwork is the key to success. Never give up!\"\n",
    "word = nltk.wordpunct_tokenize(text1)\n",
    "finder = BigramCollocationFinder.from_words(word)\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "value = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "sorted(bigram for bigram, score in value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('De', 'verzekeringsmaatschappijen')\n",
      "('verzekeringsmaatschappijen', 'verhelen')\n",
      "('verhelen', 'niet')\n",
      "('niet', 'dat')\n",
      "('dat', 'ook')\n"
     ]
    }
   ],
   "source": [
    "bigrams_tokens=ngrams(alpino.words(),2)\n",
    "\n",
    "for i, gram in enumerate(bigrams_tokens):\n",
    "    if i < 5:\n",
    "        print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('De', 'verzekeringsmaatschappijen', 'verhelen')\n",
      "('verzekeringsmaatschappijen', 'verhelen', 'niet')\n",
      "('verhelen', 'niet', 'dat')\n",
      "('niet', 'dat', 'ook')\n",
      "('dat', 'ook', 'de')\n"
     ]
    }
   ],
   "source": [
    "trigrams_tokens=ngrams(alpino.words(),3)\n",
    "\n",
    "for i, gram in enumerate(trigrams_tokens):\n",
    "    if i < 5:\n",
    "        print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hello', 'how', 'are', 'you') 1\n",
      "('how', 'are', 'you', 'doing') 1\n",
      "('are', 'you', 'doing', '?') 1\n",
      "('you', 'doing', '?', 'I') 1\n",
      "('doing', '?', 'I', 'hope') 1\n",
      "('?', 'I', 'hope', 'you') 1\n",
      "('I', 'hope', 'you', 'find') 1\n",
      "('hope', 'you', 'find', 'the') 1\n",
      "('you', 'find', 'the', 'book') 1\n",
      "('find', 'the', 'book', 'interesting') 1\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello how are you doing ? I hope you find the book interesting\"\n",
    "tokens = nltk.wordpunct_tokenize(text)\n",
    "fourgrams = nltk.collocations.QuadgramCollocationFinder.from_words(tokens)\n",
    "for fourgram, freq in fourgrams.ngram_fd.items():\n",
    "    print(fourgram,freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hello', ',', 'please', 'read', 'the')\n",
      "(',', 'please', 'read', 'the', 'book')\n",
      "('please', 'read', 'the', 'book', 'throughly')\n",
      "('read', 'the', 'book', 'throughly', '.')\n",
      "('the', 'book', 'throughly', '.', 'If')\n",
      "('book', 'throughly', '.', 'If', 'you')\n",
      "('throughly', '.', 'If', 'you', 'have')\n",
      "('.', 'If', 'you', 'have', 'any')\n",
      "('If', 'you', 'have', 'any', '\\\\')\n",
      "('you', 'have', 'any', '\\\\', 'queries')\n",
      "('have', 'any', '\\\\', 'queries', ',')\n",
      "('any', '\\\\', 'queries', ',', 'they')\n",
      "('\\\\', 'queries', ',', 'they', \"don't\")\n",
      "('queries', ',', 'they', \"don't\", 'hesitate')\n",
      "(',', 'they', \"don't\", 'hesitate', 'to')\n",
      "('they', \"don't\", 'hesitate', 'to', 'ask')\n",
      "(\"don't\", 'hesitate', 'to', 'ask', '.')\n",
      "('hesitate', 'to', 'ask', '.', 'There')\n",
      "('to', 'ask', '.', 'There', 'is')\n",
      "('ask', '.', 'There', 'is', 'no')\n",
      "('.', 'There', 'is', 'no', 'shortcut')\n",
      "('There', 'is', 'no', 'shortcut', 'to')\n",
      "('is', 'no', 'shortcut', 'to', 'success.')\n"
     ]
    }
   ],
   "source": [
    "sent=\" Hello , please read the book throughly . If you have any \\ queries , they don't hesitate to ask . There is no shortcut to success.\"\n",
    "n=5\n",
    "fivegrams = ngrams(sent.split(),n)\n",
    "for grams in fivegrams:\n",
    "    print(grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latihan 2 | Probability Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import io\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "filename = 'story2.txt'\n",
    "with io.open(filename) as fin:\n",
    "    text = fin.read()\n",
    "    \n",
    "#Tokenize the text.\n",
    "tokenized_text = [list(map(str.lower, word_tokenize(sent)))\n",
    "                  for sent in sent_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the tokenized text for 3-grams language modelling\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "\n",
    "n = 3\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)\n",
    "\n",
    "model = MLE(n) # Lets train a 3-grams maximum likelihoid estimation models.\n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in c:\\users\\user\\anaconda3\\lib\\site-packages (20.2.3)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.2.zip (177 kB)\n",
      "Building wheels for collected packages: dill\n",
      "  Building wheel for dill (setup.py): started\n",
      "  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.2-py3-none-any.whl size=77903 sha256=2620bcb2dfc2702a34e8a9747fe1f27cc23d3d1e5ab195e224d787978fdda5d9\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\02\\49\\cf\\660924cd9bc5fcddc3a0246fe39800c83028d3ccea244de352\n",
      "Successfully built dill\n",
      "Installing collected packages: dill\n",
      "Successfully installed dill-0.3.2\n",
      "Collecting nltk==3.4\n",
      "  Downloading nltk-3.4.zip (1.4 MB)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk==3.4) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: singledispatch in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk==3.4) (3.4.0.3)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py): started\n",
      "  Building wheel for nltk (setup.py): finished with status 'done'\n",
      "  Created wheel for nltk: filename=nltk-3.4-py3-none-any.whl size=1435863 sha256=4b054a86a28a6958cc5b353402a37311b9e33adf51d810a03e9984ebf7cd8703\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\82\\65\\d5\\eb94274f37176d3907fcf972069738a40e760c92049d59f07d\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.3\n",
      "    Uninstalling nltk-3.3:\n",
      "      Successfully uninstalled nltk-3.3\n",
      "Successfully installed nltk-3.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install -U dill\n",
    "!pip install -U nltk==3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts['the'] # i.e. Count('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts[['the']]['king'] # i.e. Count('king'|'the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts[['the', 'king']]['heard'] # i.e. Count('heard|'the king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30434782608695654"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score('king', 'the' .split()) # P('king|the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2857142857142857"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score('heard', 'the king' .split()) # P('heard' | 'the king')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the tokenized text for 2-grams language modelling\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "\n",
    "n = 2\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)\n",
    "\n",
    "model = MLE(n) # Lets train a 2-grams maximum likelihoid estimation models.\n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts['the'] # i.e. Count('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts[['the']]['king'] # i.e. Count('king'|'the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts[['the', 'king']]['heard'] # i.e. Count('heard|'the king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30434782608695654"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score('king', 'the' .split()) # P('king|the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score('heard', 'the king' .split()) # P('heard' | 'the king')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## quadgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the tokenized text for 4-grams language modelling\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "\n",
    "n = 4\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)\n",
    "\n",
    "model = MLE(n) # Lets train a 4-grams maximum likelihoid estimation models.\n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts['the'] # i.e. Count('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts[['the']]['king'] # i.e. Count('king'|'the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts[['the', 'king']]['heard'] # i.e. Count('heard|'the king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30434782608695654"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score('king', 'the' .split()) # P('king|the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2857142857142857"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score('heard', 'the king' .split()) # P('heard' | 'the king')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hasil pengamatan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah melakukan language modeling pada bigram dan quadgram, lalu menuliskan kode untuk mendapatkan count dan probabilitas, terdapat perbedaan hasil antara bigram, tigram dan quadgram. Pada bigram, count dari munculnya kata 'the' lalu 'king' setelah kata 'heard' adalah 0. Probabilitas dari munculnya kata 'heard' setelah kata 'the king' adalah 0. Sedangkan pada quadgram, nilai count dan probabilitas nya sama dengan trigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
